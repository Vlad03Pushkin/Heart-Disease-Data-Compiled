{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9b644db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-18 02:03:16,567 WARN util.Utils: Your hostname, localhost.localdomain resolves to a loopback address: 127.0.0.1; using 10.0.2.15 instead (on interface enp0s3)\n",
      "2024-06-18 02:03:16,568 WARN util.Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "2024-06-18 02:03:16,882 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to\n",
      "      ____              __\n",
      "     / __/__  ___ _____/ /__\n",
      "    _\\ \\/ _ \\/ _ `/ __/  '_/\n",
      "   /__ / .__/\\_,_/_/ /_/\\_\\   version 3.1.2\n",
      "      /_/\n",
      "\n",
      "Using Python version 3.8.11 (default, Aug 19 2021 15:49:35)\n",
      "Spark context Web UI available at http://10.0.2.15:4040\n",
      "Spark context available as 'sc' (master = local[*], app id = local-1718643798040).\n",
      "SparkSession available as 'spark'.\n",
      "root\n",
      " |-- Age: string (nullable = true)\n",
      " |-- Sex: string (nullable = true)\n",
      " |-- ChestPainType: string (nullable = true)\n",
      " |-- RestingBP: string (nullable = true)\n",
      " |-- Cholesterol: string (nullable = true)\n",
      " |-- FastingBS: string (nullable = true)\n",
      " |-- RestingECG: string (nullable = true)\n",
      " |-- MaxHR: string (nullable = true)\n",
      " |-- ExerciseAngina: string (nullable = true)\n",
      " |-- Oldpeak: string (nullable = true)\n",
      " |-- HeartDisease: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.shell import spark\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, DoubleType\n",
    "\n",
    "ds = spark.read.csv(\"heart_disease_dataset.csv\", header=True)\n",
    "\n",
    "# Фильтрация строк с NULL значениями в столбце \"Oldpeak\"\n",
    "ds = ds.filter(ds[\"Oldpeak\"].isNull() == False)\n",
    "\n",
    "# Просмотрим мета-данные датасета\n",
    "ds.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0fea072",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Age: integer (nullable = true)\n",
      " |-- Sex: integer (nullable = true)\n",
      " |-- ChestPainType: integer (nullable = true)\n",
      " |-- RestingBP: integer (nullable = true)\n",
      " |-- Cholesterol: integer (nullable = true)\n",
      " |-- FastingBS: integer (nullable = true)\n",
      " |-- RestingECG: integer (nullable = true)\n",
      " |-- MaxHR: integer (nullable = true)\n",
      " |-- ExerciseAngina: integer (nullable = true)\n",
      " |-- Oldpeak: double (nullable = true)\n",
      " |-- HeartDisease: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Схема определилась нерпавильно, поэтому нужно задать ее вручную в соотвествии с тимами данных в таблице\n",
    "schema = StructType([\n",
    "    StructField(\"Age\", IntegerType(), True),\n",
    "    StructField(\"Sex\", IntegerType(), True),\n",
    "    StructField(\"ChestPainType\", IntegerType(), True),\n",
    "    StructField(\"RestingBP\", IntegerType(), True),\n",
    "    StructField(\"Cholesterol\", IntegerType(), True),\n",
    "    StructField(\"FastingBS\", IntegerType(), True),\n",
    "    StructField(\"RestingECG\", IntegerType(), True),\n",
    "    StructField(\"MaxHR\", IntegerType(), True),\n",
    "    StructField(\"ExerciseAngina\", IntegerType(), True),\n",
    "    StructField(\"Oldpeak\", DoubleType(), True),\n",
    "    StructField(\"HeartDisease\", IntegerType(), True),\n",
    "\n",
    "])\n",
    "\n",
    "# Еще раз просматриваем csv файл с указанием схемы и убеждаемся, что все изменилось\n",
    "df = spark.read.csv(\"heart_disease_dataset.csv\", header=True, schema=schema)\n",
    "df.printSchema() # Все вывелось корректно"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b35fb25",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Кол-во записей для тренировки 210270\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 3:==============>                                            (1 + 3) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Кол-во записей для теста 89730\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Подготовка данных\n",
    "# Создание трансформера и его применение\n",
    "assembler = VectorAssembler(inputCols=[\"Age\", \"Sex\", \"ChestPainType\", \"RestingBP\", \"Cholesterol\", \"FastingBS\", \"RestingECG\", \"MaxHR\", \"ExerciseAngina\", \"Oldpeak\"], outputCol=\"features\")\n",
    "df = assembler.transform(df)\n",
    "\n",
    "\n",
    "# Разделяем на тестовую и обучающую выборки\n",
    "train, test = df.randomSplit([0.7, 0.3])\n",
    "\n",
    "# Проверка количества строк тренировки и теста\n",
    "print(\"Кол-во записей для тренировки\", train.count())\n",
    "print(\"Кол-во записей для теста\", test.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "59d25071",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-18 02:03:44,267 WARN util.Instrumentation: [b250f38d] regParam is zero, which might cause numerical instability and overfitting.\n",
      "2024-06-18 02:03:44,665 WARN netlib.BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeSystemBLAS\n",
      "2024-06-18 02:03:44,666 WARN netlib.BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeRefBLAS\n",
      "2024-06-18 02:03:45,192 WARN netlib.LAPACK: Failed to load implementation from: com.github.fommil.netlib.NativeSystemLAPACK\n",
      "2024-06-18 02:03:45,192 WARN netlib.LAPACK: Failed to load implementation from: com.github.fommil.netlib.NativeRefLAPACK\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+-------------+---------+-----------+---------+----------+-----+--------------+-------------------+------------+--------------------+-------------------+\n",
      "|Age|Sex|ChestPainType|RestingBP|Cholesterol|FastingBS|RestingECG|MaxHR|ExerciseAngina|            Oldpeak|HeartDisease|            features|         prediction|\n",
      "+---+---+-------------+---------+-----------+---------+----------+-----+--------------+-------------------+------------+--------------------+-------------------+\n",
      "| 20|  0|            1|       81|        208|        0|         1|   63|             0|0.27034656931119816|           0|[20.0,0.0,1.0,81....|0.41327363095489655|\n",
      "| 20|  0|            1|       81|        355|        0|         2|  120|             1| 2.4659171576119694|           0|[20.0,0.0,1.0,81....|  0.632776183039798|\n",
      "| 20|  0|            1|       82|        581|        0|         2|   97|             0| 0.3523562588174398|           0|[20.0,0.0,1.0,82....| 0.5523433793443275|\n",
      "| 20|  0|            1|       84|        243|        1|         2|   98|             0|  5.280493603093884|           1|[20.0,0.0,1.0,84....| 0.7117750766869063|\n",
      "| 20|  0|            1|       84|        431|        1|         2|  159|             1| 5.0551323580970475|           1|[20.0,0.0,1.0,84....| 0.8224749240139019|\n",
      "| 20|  0|            1|       88|        549|        1|         0|  128|             1|  4.760975529482752|           0|[20.0,0.0,1.0,88....| 0.5870693671128742|\n",
      "| 20|  0|            1|       90|        223|        1|         1|   60|             1|  1.034457950645096|           0|[20.0,0.0,1.0,90....| 0.5466372912505661|\n",
      "| 20|  0|            1|       90|        521|        1|         2|   74|             1| 1.6239321821623827|           1|[20.0,0.0,1.0,90....| 0.6562503565918396|\n",
      "| 20|  0|            1|       90|        586|        0|         2|   82|             0|   4.13114606777078|           0|[20.0,0.0,1.0,90....|  0.580453009964553|\n",
      "| 20|  0|            1|       91|        112|        1|         0|  152|             0|  4.688202915636259|           0|[20.0,0.0,1.0,91....| 0.6382438592317033|\n",
      "| 20|  0|            1|       99|        593|        0|         2|  132|             1| 3.8092718050192245|           1|[20.0,0.0,1.0,99....| 0.7013924523152368|\n",
      "| 20|  0|            1|      102|        392|        1|         1|  170|             0|  4.817170531647285|           1|[20.0,0.0,1.0,102...| 0.7791511748001936|\n",
      "| 20|  0|            1|      103|        153|        0|         2|  197|             0| 1.3802226336016614|           1|[20.0,0.0,1.0,103...| 0.8048370742232183|\n",
      "| 20|  0|            1|      103|        437|        0|         2|  167|             0|  5.386243313195249|           1|[20.0,0.0,1.0,103...| 0.7775051272406333|\n",
      "| 20|  0|            1|      108|        599|        0|         2|  155|             0| 3.9526215570684125|           1|[20.0,0.0,1.0,108...| 0.7499109160325276|\n",
      "| 20|  0|            1|      109|        274|        0|         2|   85|             0| 0.2440846846200908|           0|[20.0,0.0,1.0,109...| 0.6113637875714434|\n",
      "| 20|  0|            1|      113|        268|        1|         1|  106|             0|  5.777887339059758|           1|[20.0,0.0,1.0,113...| 0.7100806708666358|\n",
      "| 20|  0|            1|      113|        279|        0|         0|  119|             0| 4.2855767451504825|           0|[20.0,0.0,1.0,113...| 0.5318705698247537|\n",
      "| 20|  0|            1|      114|        104|        0|         0|  178|             1|  4.996616556318949|           1|[20.0,0.0,1.0,114...| 0.6648485784533015|\n",
      "| 20|  0|            1|      114|        298|        0|         1|   96|             1| 3.3821210147621006|           0|[20.0,0.0,1.0,114...| 0.5930164177993777|\n",
      "+---+---+-------------+---------+-----------+---------+----------+-----+--------------+-------------------+------------+--------------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точность линейной регрессии:  0.9995771543197074\n"
     ]
    }
   ],
   "source": [
    "# Создаем линейную регрессию\n",
    "lr = LinearRegression(featuresCol=\"features\", labelCol=\"HeartDisease\")\n",
    "\n",
    "# Обучаем модель\n",
    "lr_model = lr.fit(train)\n",
    "\n",
    "# применяем модель к тестовому набору данных\n",
    "predictions = lr_model.transform(test)\n",
    "\n",
    "predictions.show()\n",
    "\n",
    "# Вызываем оценщика\n",
    "res = BinaryClassificationEvaluator(rawPredictionCol='prediction', labelCol='HeartDisease')\n",
    "\n",
    "\n",
    "# представляет степень или показатель отделимости. ROC показывает, насколько модель способна различать классы\n",
    "ROC_AUC = res.evaluate(predictions)\n",
    "print(\"Точность линейной регрессии: \", ROC_AUC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b5570bf1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--SVM--\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точность SVM с maxIter=5: 0.50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точность SVM с maxIter=10: 0.50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точность SVM с maxIter=15: 0.51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точность SVM с maxIter=20: 0.52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точность SVM с maxIter=25: 0.71\n",
      "\n",
      "\n",
      "--Random Trees--\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точность случайных лесов с numTrees=5: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точность случайных лесов с numTrees=10: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точность случайных лесов с numTrees=15: 0.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точность случайных лесов с numTrees=20: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точность случайных лесов с numTrees=25: 0.74\n",
      "\n",
      "\n",
      "Вывод лучших результатов\n",
      "Лучшая точность SVM: 0.71 с maxIter=25\n",
      "Лучшая точность случайных лесов: 0.77 с numTrees=15\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import StringIndexer, VectorAssembler, OneHotEncoder\n",
    "from pyspark.ml.classification import RandomForestClassifier, LinearSVC\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "# Загрузка данных из файла (предполагается, что данные находятся в файле 'heart_data.csv')\n",
    "data = spark.read.csv(\"heart_disease_dataset.csv\", header=True, inferSchema=True)\n",
    "\n",
    "# Преобразование категориальных признаков в числовые\n",
    "categoricalCols = ['Sex', 'ChestPainType', 'RestingECG', 'ExerciseAngina']\n",
    "stages = []\n",
    "for categoricalCol in categoricalCols:\n",
    "    stringIndexer = StringIndexer(inputCol=categoricalCol, outputCol=categoricalCol + \"Index\")\n",
    "    encoder = OneHotEncoder(inputCols=[stringIndexer.getOutputCol()], outputCols=[categoricalCol + \"Encoded\"])\n",
    "    stages += [stringIndexer, encoder]\n",
    "\n",
    "# Создание вектора признаков\n",
    "numericCols = [\"Age\", \"Sex\", \"ChestPainType\", \"RestingBP\", \"Cholesterol\", \"FastingBS\", \"RestingECG\", \"MaxHR\", \"ExerciseAngina\", \"Oldpeak\"]\n",
    "assemblerInputs = [c + \"Encoded\" for c in categoricalCols] + numericCols\n",
    "assembler = VectorAssembler(inputCols=assemblerInputs, outputCol=\"features\")\n",
    "stages += [assembler]\n",
    "\n",
    "# Создание конвейера\n",
    "pipeline = Pipeline(stages=stages)\n",
    "\n",
    "# Разделение данных на обучающую и тестовую выборки\n",
    "(trainingData, testData) = data.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "# --- Метод SVM ---\n",
    "best_accuracy_svm = 0\n",
    "best_max_iter = 0\n",
    "\n",
    "maxIter_list = [5, 10, 15, 20, 25]\n",
    "\n",
    "print(\"--SVM--\")\n",
    "for maxIter in maxIter_list:\n",
    "    # Создание модели SVM с текущим значением maxIter\n",
    "    svm = LinearSVC(featuresCol=\"features\", labelCol=\"HeartDisease\", maxIter=maxIter)\n",
    "\n",
    "    # Обучение конвейера с моделью SVM\n",
    "    pipeline_svm = Pipeline(stages=stages + [svm])\n",
    "    svm_model = pipeline_svm.fit(trainingData)\n",
    "\n",
    "    # Предсказание на тестовой выборке с помощью SVM\n",
    "    predictions_svm = svm_model.transform(testData)\n",
    "\n",
    "    # Вычисление точности SVM\n",
    "    evaluator = BinaryClassificationEvaluator(labelCol=\"HeartDisease\", rawPredictionCol=\"prediction\")\n",
    "    accuracy_svm = evaluator.evaluate(predictions_svm)\n",
    "    print(f\"Точность SVM с maxIter={maxIter}: {accuracy_svm:.2f}\")\n",
    "\n",
    "    if accuracy_svm > best_accuracy_svm:\n",
    "        best_accuracy_svm = accuracy_svm\n",
    "        best_max_iter = maxIter\n",
    "print(\"\\n\")\n",
    "\n",
    "# --- Метод случайных лесов ---\n",
    "best_accuracy_rf = 0\n",
    "best_num_trees = 0\n",
    "\n",
    "numTrees_list = [5, 10, 15, 20, 25]\n",
    "\n",
    "print(\"--Random Trees--\")\n",
    "for numTrees in numTrees_list:\n",
    "    # Создание модели случайных лесов\n",
    "    rf = RandomForestClassifier(featuresCol=\"features\", labelCol=\"HeartDisease\", numTrees=numTrees)\n",
    "\n",
    "    # Создание конвейера для случайных лесов\n",
    "    pipeline_rf = Pipeline(stages=stages + [rf])\n",
    "\n",
    "    # Обучение модели случайных лесов\n",
    "    rf_model = pipeline_rf.fit(trainingData)\n",
    "\n",
    "    # Предсказание на тестовой выборке с помощью случайных лесов\n",
    "    predictions_rf = rf_model.transform(testData)\n",
    "\n",
    "    # Вычисление точности случайных лесов\n",
    "    accuracy_rf = evaluator.evaluate(predictions_rf)\n",
    "    print(f\"Точность случайных лесов с numTrees={numTrees}: {accuracy_rf:.2f}\")\n",
    "\n",
    "    if accuracy_rf > best_accuracy_rf:\n",
    "        best_accuracy_rf = accuracy_rf\n",
    "        best_num_trees = numTrees\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Вывод лучших результатов\")\n",
    "# Вывод результатов\n",
    "print(f\"Лучшая точность SVM: {best_accuracy_svm:.2f} с maxIter={best_max_iter}\")\n",
    "print(f\"Лучшая точность случайных лесов: {best_accuracy_rf:.2f} с numTrees={best_num_trees}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e02cdbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество мужчин и женщин с сердечными заболеваниями\n",
      "+------+-----+\n",
      "|   Sex|Count|\n",
      "+------+-----+\n",
      "|  Male|75971|\n",
      "|Female|75578|\n",
      "+------+-----+\n",
      "\n",
      "Средний возраст мужчин и женщин с сердечными заболеваниями\n",
      "+------+------------------+\n",
      "|   Sex|          avg(Age)|\n",
      "+------+------------------+\n",
      "|  Male| 50.09166655697569|\n",
      "|Female|49.925785281431104|\n",
      "+------+------------------+\n",
      "\n",
      "Средний уровень холестерина у мужчин и женщин с сердечными заболеваниями\n",
      "+------+------------------+\n",
      "|   Sex|  avg(Cholesterol)|\n",
      "+------+------------------+\n",
      "|  Male|347.80468863118824|\n",
      "|Female| 349.0907539230993|\n",
      "+------+------------------+\n",
      "\n",
      "Количество людей с ангиной среди мужчин и женщин с сердечными заболеваниями\n",
      "+------+-----+\n",
      "|   Sex|Count|\n",
      "+------+-----+\n",
      "|  Male|19054|\n",
      "|Female|18893|\n",
      "+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, count, when\n",
    "\n",
    "# Загружаем данные\n",
    "df = spark.read.csv(\"disease_dataset.csv\", header=True, inferSchema=True)\n",
    "\n",
    "# Подсчитываем количество мужчин и женщин с сердечными заболеваниями\n",
    "heart_disease_counts = df.filter(col(\"HeartDisease\") == 1) \\\n",
    "    .groupBy(\"Sex\") \\\n",
    "    .agg(count(\"HeartDisease\").alias(\"Count\")) \\\n",
    "    .withColumn(\"Sex\", when(col(\"Sex\") == 1, \"Male\").otherwise(\"Female\"))\n",
    "\n",
    "print(\"Количество мужчин и женщин с сердечными заболеваниями\")\n",
    "# Выводим результаты\n",
    "heart_disease_counts.show()\n",
    "\n",
    "# Дополнительные виды анализа\n",
    "\n",
    "# 1. Средний возраст мужчин и женщин с сердечными заболеваниями\n",
    "avg_age = df.filter(col(\"HeartDisease\") == 1) \\\n",
    "    .groupBy(\"Sex\") \\\n",
    "    .agg({\"Age\": \"avg\"}) \\\n",
    "    .withColumn(\"Sex\", when(col(\"Sex\") == 1, \"Male\").otherwise(\"Female\"))\n",
    "\n",
    "print(\"Средний возраст мужчин и женщин с сердечными заболеваниями\")\n",
    "avg_age.show()\n",
    "\n",
    "# 2. Средний уровень холестерина у мужчин и женщин с сердечными заболеваниями\n",
    "avg_cholesterol = df.filter(col(\"HeartDisease\") == 1) \\\n",
    "    .groupBy(\"Sex\") \\\n",
    "    .agg({\"Cholesterol\": \"avg\"}) \\\n",
    "    .withColumn(\"Sex\", when(col(\"Sex\") == 1, \"Male\").otherwise(\"Female\"))\n",
    "\n",
    "print(\"Средний уровень холестерина у мужчин и женщин с сердечными заболеваниями\")\n",
    "avg_cholesterol.show()\n",
    "\n",
    "# 3. Количество людей с типичной ангиной среди мужчин и женщин с сердечными заболеваниями\n",
    "chest_pain_counts = df.filter((col(\"HeartDisease\") == 1) & (col(\"ChestPainType\") == 1)) \\\n",
    "    .groupBy(\"Sex\") \\\n",
    "    .agg(count(\"ChestPainType\").alias(\"Count\")) \\\n",
    "    .withColumn(\"Sex\", when(col(\"Sex\") == 1, \"Male\").otherwise(\"Female\"))\n",
    "\n",
    "print(\"Количество людей с ангиной среди мужчин и женщин с сердечными заболеваниями\")\n",
    "chest_pain_counts.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "febf113f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
